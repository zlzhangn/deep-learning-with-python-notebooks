{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQ8RZ0o5vKU"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-RQegMO5vKV"
      },
      "outputs": [],
      "source": [
        "!pip install keras keras-hub --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_8wfDJH5vKV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Avrfph6w5vKV"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZziaz_E5vKV"
      },
      "source": [
        "## A deep dive on Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhfjLU_i5vKV"
      },
      "source": [
        "### A spectrum of workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKyjsKfm5vKV"
      },
      "source": [
        "### Different ways to build Keras models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z6YmH-r5vKV"
      },
      "source": [
        "#### The Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP3Y6VBL5vKV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR9cYrqY5vKV"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qo0fQtk5vKV"
      },
      "outputs": [],
      "source": [
        "model.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtPMPgXw5vKV"
      },
      "outputs": [],
      "source": [
        "model.build(input_shape=(None, 3))\n",
        "model.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnMk9V-V5vKV"
      },
      "outputs": [],
      "source": [
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFe3jAFb5vKW"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(name=\"my_example_model\")\n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
        "model.build((None, 3))\n",
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFKe-yaS5vKW"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(3,)))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SDrzCAs5vKW"
      },
      "outputs": [],
      "source": [
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdMHSl-o5vKW"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQFEB2gc5vKW"
      },
      "source": [
        "#### The Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KIjeLE-5vKW"
      },
      "source": [
        "##### A simple example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb1Lw_gf5vKW"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_functional_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O_NdTWP5vKW"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoU_GEhH5vKW"
      },
      "outputs": [],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cuvRQJU5vKW"
      },
      "outputs": [],
      "source": [
        "inputs.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaK8YWKy5vKW"
      },
      "outputs": [],
      "source": [
        "features = layers.Dense(64, activation=\"relu\")(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeGzl14x5vKW"
      },
      "outputs": [],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpU7946z5vKW"
      },
      "outputs": [],
      "source": [
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_functional_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxA6Xf4F5vKW"
      },
      "outputs": [],
      "source": [
        "model.summary(line_length=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43-eiNaq5vKW"
      },
      "source": [
        "##### Multi-input, multi-output models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awYRXteZ5vKW"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 10000\n",
        "num_tags = 100\n",
        "num_departments = 4\n",
        "\n",
        "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
        "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
        "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
        "\n",
        "features = layers.Concatenate()([title, text_body, tags])\n",
        "features = layers.Dense(64, activation=\"relu\", name=\"dense_features\")(features)\n",
        "\n",
        "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
        "department = layers.Dense(\n",
        "    num_departments, activation=\"softmax\", name=\"department\"\n",
        ")(features)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs=[title, text_body, tags],\n",
        "    outputs=[priority, department],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z40LZs6d5vKW"
      },
      "source": [
        "##### Training a multi-input, multi-output model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV55dv8b5vKW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1280\n",
        "\n",
        "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
        "\n",
        "priority_data = np.random.random(size=(num_samples, 1))\n",
        "department_data = np.random.randint(0, num_departments, size=(num_samples, 1))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=[\"mean_squared_error\", \"sparse_categorical_crossentropy\"],\n",
        "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]],\n",
        ")\n",
        "model.fit(\n",
        "    [title_data, text_body_data, tags_data],\n",
        "    [priority_data, department_data],\n",
        "    epochs=1,\n",
        ")\n",
        "model.evaluate(\n",
        "    [title_data, text_body_data, tags_data], [priority_data, department_data]\n",
        ")\n",
        "priority_preds, department_preds = model.predict(\n",
        "    [title_data, text_body_data, tags_data]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzlGjDWX5vKW"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\n",
        "        \"priority\": \"mean_squared_error\",\n",
        "        \"department\": \"sparse_categorical_crossentropy\",\n",
        "    },\n",
        "    metrics={\n",
        "        \"priority\": [\"mean_absolute_error\"],\n",
        "        \"department\": [\"accuracy\"],\n",
        "    },\n",
        ")\n",
        "model.fit(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "    {\"priority\": priority_data, \"department\": department_data},\n",
        "    epochs=1,\n",
        ")\n",
        "model.evaluate(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "    {\"priority\": priority_data, \"department\": department_data},\n",
        ")\n",
        "priority_preds, department_preds = model.predict(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o0WdgFn5vKX"
      },
      "source": [
        "##### The power of the Functional API: Access to layer connectivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_nIJnG05vKX"
      },
      "source": [
        "###### Plotting layer connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAd8oPHA5vKX"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdSX8Ah35vKX"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(\n",
        "    model,\n",
        "    \"ticket_classifier_with_shape_info.png\",\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oLg-VL15vKX"
      },
      "source": [
        "###### Feature extraction with a Functional model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNBPB6Vj5vKX"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsgoyhrr5vKX"
      },
      "outputs": [],
      "source": [
        "model.layers[3].input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDvT5QgY5vKX"
      },
      "outputs": [],
      "source": [
        "model.layers[3].output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr2tPwS85vKX"
      },
      "outputs": [],
      "source": [
        "features = model.layers[4].output\n",
        "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
        "\n",
        "new_model = keras.Model(\n",
        "    inputs=[title, text_body, tags], outputs=[priority, department, difficulty]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVzZmdVw5vKX"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(\n",
        "    new_model,\n",
        "    \"updated_ticket_classifier.png\",\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sajAV1695vKX"
      },
      "source": [
        "#### Subclassing the Model class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFh6aFhi5vKX"
      },
      "source": [
        "##### Rewriting our previous example as a subclassed model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW-lKe7z5vKX"
      },
      "outputs": [],
      "source": [
        "class CustomerTicketModel(keras.Model):\n",
        "    def __init__(self, num_departments):\n",
        "        super().__init__()\n",
        "        self.concat_layer = layers.Concatenate()\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.department_classifier = layers.Dense(\n",
        "            num_departments, activation=\"softmax\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        title = inputs[\"title\"]\n",
        "        text_body = inputs[\"text_body\"]\n",
        "        tags = inputs[\"tags\"]\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags])\n",
        "        features = self.mixing_layer(features)\n",
        "        priority = self.priority_scorer(features)\n",
        "        department = self.department_classifier(features)\n",
        "        return priority, department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pwP3Rsb5vKX"
      },
      "outputs": [],
      "source": [
        "model = CustomerTicketModel(num_departments=4)\n",
        "\n",
        "priority, department = model(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smZfKLiS5vKX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=[\"mean_squared_error\", \"sparse_categorical_crossentropy\"],\n",
        "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]],\n",
        ")\n",
        "model.fit(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "    [priority_data, department_data],\n",
        "    epochs=1,\n",
        ")\n",
        "model.evaluate(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "    [priority_data, department_data],\n",
        ")\n",
        "priority_preds, department_preds = model.predict(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjJpg3i45vKX"
      },
      "source": [
        "##### Beware: What subclassed models don't support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VEomEk5vKX"
      },
      "source": [
        "#### Mixing and matching different components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlEEA8tZ5vKX"
      },
      "outputs": [],
      "source": [
        "class Classifier(keras.Model):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        if num_classes == 2:\n",
        "            num_units = 1\n",
        "            activation = \"sigmoid\"\n",
        "        else:\n",
        "            num_units = num_classes\n",
        "            activation = \"softmax\"\n",
        "        self.dense = layers.Dense(num_units, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = Classifier(num_classes=10)(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZAZL8435vKX"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(64,))\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
        "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.dense = layers.Dense(64, activation=\"relu\")\n",
        "        self.classifier = binary_classifier\n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.dense(inputs)\n",
        "        return self.classifier(features)\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFVfV1KJ5vKX"
      },
      "source": [
        "#### Remember: Use the right tool for the job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhRCHRSc5vKY"
      },
      "source": [
        "### Using built-in training and evaluation loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH1kGqI95vKY"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]\n",
        "\n",
        "model = get_mnist_model()\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_images, val_labels),\n",
        ")\n",
        "test_metrics = model.evaluate(test_images, test_labels)\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe7sYFBh5vKY"
      },
      "source": [
        "#### Writing your own metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zvP4IASHwqqf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vkdxYhK5vKY"
      },
      "outputs": [],
      "source": [
        "from keras import ops\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(\n",
        "            name=\"total_samples\", initializer=\"zeros\"\n",
        "        )\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = ops.one_hot(y_true, num_classes=ops.shape(y_pred)[1])\n",
        "        mse = ops.sum(ops.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        num_samples = ops.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return ops.sqrt(self.mse_sum / self.total_samples)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGf16k9t5vKY"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\", RootMeanSquaredError()],\n",
        ")\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_images, val_labels),\n",
        ")\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ä»£ç è§£é‡Š"
      ],
      "metadata": {
        "id": "TuFLAgzrxSVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„ **Keras æŒ‡æ ‡ï¼ˆMetricï¼‰ç±»** â€”â€” `RootMeanSquaredError`ï¼ˆRMSEï¼Œå‡æ–¹æ ¹è¯¯å·®ï¼‰ï¼Œå®ƒç»§æ‰¿è‡ª `keras.metrics.Metric`ã€‚\n",
        "æˆ‘ä»¬é€è¡Œæ¥è§£é‡Šï¼š\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸŒ± 1ï¸âƒ£ å¯¼å…¥ä¸ç±»å®šä¹‰\n",
        "\n",
        "```python\n",
        "from keras import ops\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "```\n",
        "\n",
        "* `keras.metrics.Metric` æ˜¯æ‰€æœ‰è‡ªå®šä¹‰æŒ‡æ ‡çš„åŸºç±»ã€‚\n",
        "* `ops` æ˜¯ Keras çš„åç«¯æ“ä½œæ¨¡å—ï¼ˆå…¼å®¹ TensorFlowã€JAXã€Torchï¼‰ï¼Œæä¾›äº†å¦‚ `ops.sum()`ã€`ops.sqrt()` ç­‰å¼ é‡è¿ç®—ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸŒ¿ 2ï¸âƒ£ åˆå§‹åŒ–æ–¹æ³• `__init__`\n",
        "\n",
        "```python\n",
        "def __init__(self, name=\"rmse\", **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "    self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\")\n",
        "```\n",
        "\n",
        "* `name=\"rmse\"` ç»™æŒ‡æ ‡å‘½åï¼Œè®­ç»ƒæ—¶å¯ä»¥ç”¨ `metrics=[\"rmse\"]` è°ƒç”¨ã€‚\n",
        "* `self.add_weight()` å®šä¹‰ä¸¤ä¸ª**çŠ¶æ€å˜é‡ï¼ˆstate variablesï¼‰**ï¼Œåœ¨æ¯ä¸ª batch æ›´æ–°ï¼š\n",
        "\n",
        "  * `mse_sum`ï¼šç´¯è®¡æ‰€æœ‰æ ·æœ¬çš„å¹³æ–¹è¯¯å·®å’Œ\n",
        "  * `total_samples`ï¼šç´¯è®¡æ ·æœ¬æ•°\n",
        "* åˆå§‹åŒ–ä¸º 0ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸƒ 3ï¸âƒ£ æ›´æ–°çŠ¶æ€ `update_state`\n",
        "\n",
        "```python\n",
        "def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = ops.one_hot(y_true, num_classes=ops.shape(y_pred)[1])\n",
        "    mse = ops.sum(ops.square(y_true - y_pred))\n",
        "    self.mse_sum.assign_add(mse)\n",
        "    num_samples = ops.shape(y_pred)[0]\n",
        "    self.total_samples.assign_add(num_samples)\n",
        "```\n",
        "\n",
        "æ¯å¤„ç†ä¸€ä¸ª batchï¼ŒKeras ä¼šè°ƒç”¨ä¸€æ¬¡ `update_state()` æ¥æ›´æ–°æŒ‡æ ‡å€¼ã€‚\n",
        "\n",
        "* `y_true = ops.one_hot(...)`\n",
        "  å°†æ ‡ç­¾è½¬ä¸º one-hot å‘é‡ï¼ˆå› ä¸ºé¢„æµ‹è¾“å‡ºæ˜¯ softmaxï¼‰ã€‚\n",
        "  æ¯”å¦‚ y_true = `[1, 2]` â†’ one-hot â†’ `[[0,1,0], [0,0,1]]`\n",
        "\n",
        "* `ops.square(y_true - y_pred)`ï¼šè®¡ç®—é€å…ƒç´ å¹³æ–¹è¯¯å·®ã€‚\n",
        "\n",
        "* `ops.sum(...)`ï¼šå¯¹æ•´ä¸ª batch æ±‚å’Œï¼Œå¾—åˆ°è¯¥ batch çš„æ€»å¹³æ–¹è¯¯å·®ã€‚\n",
        "\n",
        "* `assign_add()`ï¼šç´¯åŠ åˆ°å…¨å±€çš„ `mse_sum` å’Œ `total_samples`ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸŒ¸ 4ï¸âƒ£ è®¡ç®—ç»“æœ `result`\n",
        "\n",
        "```python\n",
        "def result(self):\n",
        "    return ops.sqrt(self.mse_sum / self.total_samples)\n",
        "```\n",
        "\n",
        "* è®¡ç®—æ•´ä½“ RMSE = âˆš(MSE)ï¼Œå³å‡æ–¹è¯¯å·®çš„å¹³æ–¹æ ¹ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸ‚ 5ï¸âƒ£ é‡ç½®çŠ¶æ€ `reset_state`\n",
        "\n",
        "```python\n",
        "def reset_state(self):\n",
        "    self.mse_sum.assign(0.)\n",
        "    self.total_samples.assign(0.)\n",
        "```\n",
        "\n",
        "* æ¯ä¸ª epoch ç»“æŸåï¼ŒKeras ä¼šè°ƒç”¨æ­¤æ–¹æ³•æ¸…é›¶çŠ¶æ€ï¼Œé¿å…è·¨ epoch æ··æ·†ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "##### âœ… 6ï¸âƒ£ æ€»ç»“æµç¨‹å›¾\n",
        "\n",
        "```\n",
        "åˆå§‹åŒ–ï¼š\n",
        "  mse_sum = 0, total_samples = 0\n",
        "\n",
        "æ¯æ‰¹æ¬¡ï¼š\n",
        "  è®¡ç®—å½“å‰ batch çš„å¹³æ–¹è¯¯å·® â†’ ç´¯åŠ åˆ° mse_sum\n",
        "  è®¡ç®—æ ·æœ¬æ•° â†’ ç´¯åŠ åˆ° total_samples\n",
        "\n",
        "æœ€ç»ˆç»“æœï¼š\n",
        "  rmse = sqrt(mse_sum / total_samples)\n",
        "\n",
        "epoch ç»“æŸï¼š\n",
        "  reset_state()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##### ğŸ“˜ ä½¿ç”¨ç¤ºä¾‹\n",
        "\n",
        "```python\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[RootMeanSquaredError()]\n",
        ")\n",
        "```\n",
        "\n",
        "è®­ç»ƒæ—¶ï¼ŒKeras ä¼šè‡ªåŠ¨ï¼š\n",
        "\n",
        "* åœ¨æ¯ä¸ª batch è°ƒç”¨ `update_state`\n",
        "* åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è®¡ç®— `result`\n",
        "* åœ¨æ–° epoch å¼€å§‹æ—¶è°ƒç”¨ `reset_state`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GGSmgILPxIP4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA8Fx3595vKY"
      },
      "source": [
        "#### Using callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIElkjYB5vKY"
      },
      "source": [
        "##### The EarlyStopping and ModelCheckpoint callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxDR3r7p5vKY"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"accuracy\",\n",
        "        patience=1,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"checkpoint_path.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "    ),\n",
        "]\n",
        "model = get_mnist_model()\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=(val_images, val_labels),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC4OLu6E5vKY"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOUpuDNp5vKY"
      },
      "source": [
        "#### Writing your own callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwKyhoQS5vKY"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.per_batch_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        plt.clf()\n",
        "        plt.plot(\n",
        "            range(len(self.per_batch_losses)),\n",
        "            self.per_batch_losses,\n",
        "            label=\"Training loss for each batch\",\n",
        "        )\n",
        "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"plot_at_epoch_{epoch}\", dpi=300)\n",
        "        self.per_batch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aYDRWyS5vKY"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    callbacks=[LossHistory()],\n",
        "    validation_data=(val_images, val_labels),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPg9SI8t5vKY"
      },
      "source": [
        "#### Monitoring and visualization with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33T7PCl45vKY"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(\n",
        "    log_dir=\"/full_path_to_your_log_dir\",\n",
        ")\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    callbacks=[tensorboard],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhBMSppE5vKY"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /full_path_to_your_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4G7XjkH5vKY"
      },
      "source": [
        "### Writing your own training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrqzNlT5vKY"
      },
      "source": [
        "#### Training vs. inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJT86C-B5vKY"
      },
      "source": [
        "#### Writing custom training step functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn6eZgLs5vKY"
      },
      "source": [
        "##### A TensorFlow training step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEauTdH-5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "model = get_mnist_model()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply(gradients, model.trainable_weights)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z6AJemq5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "batch_size = 32\n",
        "inputs = train_images[:batch_size]\n",
        "targets = train_labels[:batch_size]\n",
        "loss = train_step(inputs, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ä»£ç è§£é‡Š"
      ],
      "metadata": {
        "id": "KGbLTE-TykZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç å±•ç¤ºäº† **Keras + TensorFlow è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼ˆcustom training loopï¼‰** çš„åŸºæœ¬åŸç†ã€‚\n",
        "æˆ‘ä»¬é€è¡Œæ¥çœ‹å®ƒåšäº†ä»€ä¹ˆï¼š\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸŒ± 1ï¸âƒ£ ç¯å¢ƒä¸å‡†å¤‡\n",
        "\n",
        "```python\n",
        "%%backend tensorflow\n",
        "import tensorflow as tf\n",
        "```\n",
        "\n",
        "* `%%backend tensorflow` æ˜¯ Jupyter é­”æ³•å‘½ä»¤ï¼ŒæŒ‡å®šåç«¯ä½¿ç”¨ TensorFlowã€‚\n",
        "* `import tensorflow as tf` å¯¼å…¥ TensorFlow åº“ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸŒ¿ 2ï¸âƒ£ åˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨\n",
        "\n",
        "```python\n",
        "model = get_mnist_model()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam()\n",
        "```\n",
        "\n",
        "* `get_mnist_model()` æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰å‡½æ•°ï¼ˆå‡è®¾å®šä¹‰åœ¨å‰é¢ï¼‰ï¼Œè¿”å›ä¸€ä¸ª MNIST åˆ†ç±»æ¨¡å‹ï¼ˆæ¯”å¦‚å·ç§¯ç½‘ç»œæˆ–å…¨è¿æ¥ç½‘ç»œï¼‰ã€‚\n",
        "* `loss_fn` æ˜¯ç¨€ç–åˆ†ç±»äº¤å‰ç†µï¼š\n",
        "\n",
        "  * é€‚ç”¨äºæ•´æ•°æ ‡ç­¾çš„å¤šåˆ†ç±»é—®é¢˜ï¼›\n",
        "  * è¾“å…¥æ ‡ç­¾å¦‚ `[3, 1, 7, ...]`ï¼›\n",
        "  * è¾“å‡ºé¢„æµ‹ä¸º softmax æ¦‚ç‡åˆ†å¸ƒã€‚\n",
        "* `optimizer = Adam()` ç”¨æ¥æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸƒ 3ï¸âƒ£ å®šä¹‰è®­ç»ƒæ­¥éª¤å‡½æ•°\n",
        "\n",
        "```python\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "```\n",
        "\n",
        "######## âœ³ï¸ `tf.GradientTape()` çš„ä½œç”¨\n",
        "\n",
        "* è¿™æ˜¯ TensorFlow çš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶ï¼›\n",
        "* å®ƒ**è®°å½•**æ¨¡å‹å‰å‘ä¼ æ’­ä¸­æ¶‰åŠçš„æ‰€æœ‰å¯è®­ç»ƒå˜é‡ï¼›\n",
        "* ä¹‹åå¯ä»¥è°ƒç”¨ `tape.gradient()` è‡ªåŠ¨è®¡ç®—è¿™äº›å˜é‡çš„æ¢¯åº¦ã€‚\n",
        "\n",
        "æµç¨‹ï¼š\n",
        "\n",
        "1. **å‰å‘ä¼ æ’­ï¼ˆforward passï¼‰**\n",
        "   `predictions = model(inputs, training=True)`\n",
        "   æ¨¡å‹åœ¨è®­ç»ƒæ¨¡å¼ä¸‹æ‰§è¡Œå‰å‘è®¡ç®—ï¼›\n",
        "2. **è®¡ç®—æŸå¤±ï¼ˆlossï¼‰**\n",
        "   `loss_fn(targets, predictions)` è®¡ç®—é¢„æµ‹ä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„è¯¯å·®ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸ€ 4ï¸âƒ£ è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æƒé‡\n",
        "\n",
        "```python\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply(gradients, model.trainable_weights)\n",
        "```\n",
        "\n",
        "* `tape.gradient(loss, model.trainable_weights)`\n",
        "  è‡ªåŠ¨è®¡ç®—æŸå¤±ç›¸å¯¹äºæ¯ä¸ªå¯è®­ç»ƒå‚æ•°çš„æ¢¯åº¦ã€‚\n",
        "* `optimizer.apply(gradients, model.trainable_weights)`\n",
        "  å°†æ¢¯åº¦åº”ç”¨äºå‚æ•°ï¼ˆå³æ‰§è¡Œä¸€æ¬¡åå‘ä¼ æ’­ + å‚æ•°æ›´æ–°ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸŒ¸ 5ï¸âƒ£ è¿”å›æŸå¤±\n",
        "\n",
        "```python\n",
        "    return loss\n",
        "```\n",
        "\n",
        "æ¯æ¬¡è°ƒç”¨ `train_step()`ï¼Œæ¨¡å‹ä¼šå®Œæˆï¼š\n",
        "\n",
        "1. å‰å‘ä¼ æ’­\n",
        "2. è®¡ç®—æŸå¤±\n",
        "3. è‡ªåŠ¨æ±‚æ¢¯åº¦\n",
        "4. æ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼ˆå‚æ•°æ›´æ–°ï¼‰\n",
        "5. è¿”å›å½“å‰ batch çš„æŸå¤±å€¼\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸ” 6ï¸âƒ£ åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨\n",
        "\n",
        "ä½ å¯ä»¥åƒè¿™æ ·è°ƒç”¨å®ƒï¼š\n",
        "\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch, y_batch)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss_value.numpy():.4f}\")\n",
        "```\n",
        "\n",
        "è¿™æ ·ä½ å°±å®ç°äº†ä¸€ä¸ªå®Œå…¨**è‡ªå®šä¹‰çš„è®­ç»ƒå¾ªç¯**ã€‚\n",
        "ç›¸æ¯” `model.fit()`ï¼Œè¿™ç§æ–¹å¼èƒ½ï¼š\n",
        "\n",
        "* å®Œå…¨æ§åˆ¶è®­ç»ƒé€»è¾‘ï¼›\n",
        "* åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥ç‰¹æ®Šæ“ä½œï¼ˆå¦‚æ¢¯åº¦è£å‰ªã€å¯¹æŠ—è®­ç»ƒã€å¯è§†åŒ–ç­‰ï¼‰ï¼›\n",
        "* ä¾¿äºç ”ç©¶å®éªŒæ€§ç½‘ç»œç»“æ„ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "######## âœ… æ€»ç»“é€»è¾‘æµç¨‹å›¾ï¼š\n",
        "\n",
        "```\n",
        "train_step(inputs, targets):\n",
        "    1. å¼€å§‹è®°å½•è®¡ç®—å›¾ (tf.GradientTape)\n",
        "    2. å‰å‘ä¼ æ’­: predictions = model(inputs)\n",
        "    3. è®¡ç®—æŸå¤±: loss = loss_fn(targets, predictions)\n",
        "    4. è‡ªåŠ¨å¾®åˆ†: gradients = tape.gradient(loss, model.weights)\n",
        "    5. åº”ç”¨æ¢¯åº¦: optimizer.apply(gradients, model.weights)\n",
        "    6. è¿”å›å½“å‰ loss\n",
        "```\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VmAmUFb7zvF4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M1-EPVQ5vKZ"
      },
      "source": [
        "##### A PyTorch training step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQxldOTt5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "import torch\n",
        "\n",
        "model = get_mnist_model()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "    predictions = model(inputs, training=True)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "    loss.backward()\n",
        "    gradients = [weight.value.grad for weight in model.trainable_weights]\n",
        "    with torch.no_grad():\n",
        "        optimizer.apply(gradients, model.trainable_weights)\n",
        "    model.zero_grad()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkAYsW745vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "batch_size = 32\n",
        "inputs = train_images[:batch_size]\n",
        "targets = train_labels[:batch_size]\n",
        "loss = train_step(inputs, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lx1ZEDm5vKZ"
      },
      "source": [
        "##### A JAX training step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs90gob85vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "model = get_mnist_model()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def compute_loss_and_updates(\n",
        "    trainable_variables, non_trainable_variables, inputs, targets\n",
        "):\n",
        "    outputs, non_trainable_variables = model.stateless_call(\n",
        "        trainable_variables, non_trainable_variables, inputs, training=True\n",
        "    )\n",
        "    loss = loss_fn(targets, outputs)\n",
        "    return loss, non_trainable_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD6tmvM45vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "import jax\n",
        "\n",
        "grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPqAKU3c5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "optimizer = keras.optimizers.Adam()\n",
        "optimizer.build(model.trainable_variables)\n",
        "\n",
        "def train_step(state, inputs, targets):\n",
        "    (trainable_variables, non_trainable_variables, optimizer_variables) = state\n",
        "    (loss, non_trainable_variables), grads = grad_fn(\n",
        "        trainable_variables, non_trainable_variables, inputs, targets\n",
        "    )\n",
        "    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
        "        optimizer_variables, grads, trainable_variables\n",
        "    )\n",
        "    return loss, (\n",
        "        trainable_variables,\n",
        "        non_trainable_variables,\n",
        "        optimizer_variables,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGRdmwfz5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "batch_size = 32\n",
        "inputs = train_images[:batch_size]\n",
        "targets = train_labels[:batch_size]\n",
        "\n",
        "trainable_variables = [v.value for v in model.trainable_variables]\n",
        "non_trainable_variables = [v.value for v in model.non_trainable_variables]\n",
        "optimizer_variables = [v.value for v in optimizer.variables]\n",
        "\n",
        "state = (trainable_variables, non_trainable_variables, optimizer_variables)\n",
        "loss, state = train_step(state, inputs, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnddI84q5vKZ"
      },
      "source": [
        "#### Low-level usage of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzVVCvD95vKZ"
      },
      "outputs": [],
      "source": [
        "from keras import ops\n",
        "\n",
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "targets = ops.array([0, 1, 2])\n",
        "predictions = ops.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "metric.update_state(targets, predictions)\n",
        "current_result = metric.result()\n",
        "print(f\"result: {current_result:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYlBQUE75vKZ"
      },
      "outputs": [],
      "source": [
        "values = ops.array([0, 1, 2, 3, 4])\n",
        "mean_tracker = keras.metrics.Mean()\n",
        "for value in values:\n",
        "    mean_tracker.update_state(value)\n",
        "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5R2ljqj5vKZ"
      },
      "outputs": [],
      "source": [
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "targets = ops.array([0, 1, 2])\n",
        "predictions = ops.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "\n",
        "metric_variables = metric.variables\n",
        "metric_variables = metric.stateless_update_state(\n",
        "    metric_variables, targets, predictions\n",
        ")\n",
        "current_result = metric.stateless_result(metric_variables)\n",
        "print(f\"result: {current_result:.2f}\")\n",
        "\n",
        "metric_variables = metric.stateless_reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ä»£ç è§£é‡Š"
      ],
      "metadata": {
        "id": "M7KX4xRZ1XWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½ ğŸ‘ï¼Œè¿™æ®µä»£ç æ¼”ç¤ºäº† **Keras æŒ‡æ ‡ï¼ˆMetricï¼‰å¯¹è±¡çš„å·¥ä½œåŸç†** â€”â€”\n",
        "ä»¥ `SparseCategoricalAccuracy`ï¼ˆç¨€ç–åˆ†ç±»å‡†ç¡®ç‡ï¼‰ä¸ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•æ‰‹åŠ¨è®¡ç®—æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®ç‡ã€‚\n",
        "æˆ‘ä»¬ä¸€æ­¥æ­¥æ¥çœ‹ ğŸ‘‡\n",
        "\n",
        "---\n",
        "\n",
        "###### ğŸ§© 1ï¸âƒ£ å¯¼å…¥ ops å¹¶åˆ›å»ºæŒ‡æ ‡å¯¹è±¡\n",
        "\n",
        "```python\n",
        "from keras import ops\n",
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "```\n",
        "\n",
        "* `ops` æ˜¯ Keras åç«¯çš„é€šç”¨æ“ä½œæ¥å£ï¼ˆåœ¨ä¸åŒåç«¯å¦‚ TensorFlowã€JAXã€PyTorch ä¸­ä¿æŒä¸€è‡´çš„ APIï¼‰ã€‚\n",
        "* `keras.metrics.SparseCategoricalAccuracy()` è¡¨ç¤ºç¨€ç–åˆ†ç±»å‡†ç¡®ç‡ï¼š\n",
        "\n",
        "  * ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡ï¼›\n",
        "  * çœŸå®æ ‡ç­¾ (`y_true`) æ˜¯æ•´æ•°ç´¢å¼•ï¼Œå¦‚ `[0, 1, 2]`ï¼›\n",
        "  * é¢„æµ‹ç»“æœ (`y_pred`) æ˜¯ softmax æ¦‚ç‡å‘é‡ï¼Œå¦‚ `[[0.8, 0.1, 0.1], ...]`ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "###### ğŸ“Š 2ï¸âƒ£ æ„é€ æµ‹è¯•æ•°æ®\n",
        "\n",
        "```python\n",
        "targets = ops.array([0, 1, 2])\n",
        "predictions = ops.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "```\n",
        "\n",
        "* `targets`ï¼šçœŸå®ç±»åˆ«ä¸º\n",
        "\n",
        "  ```\n",
        "  æ ·æœ¬1 â†’ ç±»åˆ«0  \n",
        "  æ ·æœ¬2 â†’ ç±»åˆ«1  \n",
        "  æ ·æœ¬3 â†’ ç±»åˆ«2\n",
        "  ```\n",
        "* `predictions`ï¼šæ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡å‘é‡\n",
        "\n",
        "  ```\n",
        "  æ ·æœ¬1é¢„æµ‹ä¸ºç±»0ï¼ˆæ¦‚ç‡æœ€é«˜ï¼‰  \n",
        "  æ ·æœ¬2é¢„æµ‹ä¸ºç±»1  \n",
        "  æ ·æœ¬3é¢„æµ‹ä¸ºç±»2\n",
        "  ```\n",
        "\n",
        "  å› æ­¤ï¼Œé¢„æµ‹æ˜¯å®Œå…¨æ­£ç¡®çš„ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "###### âš™ï¸ 3ï¸âƒ£ æ›´æ–°æŒ‡æ ‡çŠ¶æ€\n",
        "\n",
        "```python\n",
        "metric.update_state(targets, predictions)\n",
        "```\n",
        "\n",
        "####### è¿™ä¸€æ­¥çš„ä½œç”¨ï¼š\n",
        "\n",
        "* `update_state()` ä¼šæ¯”è¾ƒçœŸå®æ ‡ç­¾ä¸é¢„æµ‹ç»“æœï¼›\n",
        "* å†…éƒ¨è®¡ç®—ï¼š\n",
        "\n",
        "  1. `pred_class = argmax(predictions, axis=-1)` â†’ `[0, 1, 2]`\n",
        "  2. ä¸ `targets` `[0, 1, 2]` æ¯”è¾ƒï¼›\n",
        "  3. åŒ¹é…æˆåŠŸçš„æ ·æœ¬æ•° = 3ï¼›\n",
        "  4. æ€»æ ·æœ¬æ•° = 3ï¼›\n",
        "  5. æš‚å­˜åˆ°å†…éƒ¨çŠ¶æ€ï¼ˆ`metric.total`, `metric.count`ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "###### ğŸ“ˆ 4ï¸âƒ£ è·å–è®¡ç®—ç»“æœ\n",
        "\n",
        "```python\n",
        "current_result = metric.result()\n",
        "```\n",
        "\n",
        "* `result()` æ ¹æ®å†…éƒ¨çŠ¶æ€è®¡ç®—å‡†ç¡®ç‡ï¼š\n",
        "  [\n",
        "  \\text{accuracy} = \\frac{\\text{æ­£ç¡®æ ·æœ¬æ•°}}{\\text{æ€»æ ·æœ¬æ•°}} = \\frac{3}{3} = 1.0\n",
        "  ]\n",
        "\n",
        "---\n",
        "\n",
        "###### ğŸ–¨ï¸ 5ï¸âƒ£ æ‰“å°ç»“æœ\n",
        "\n",
        "```python\n",
        "print(f\"result: {current_result:.2f}\")\n",
        "```\n",
        "\n",
        "è¾“å‡ºï¼š\n",
        "\n",
        "```\n",
        "result: 1.00\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "###### âœ… æ€»ç»“æµç¨‹\n",
        "\n",
        "| æ­¥éª¤ | å‡½æ•°                                                   | å«ä¹‰                   |\n",
        "| -- | ---------------------------------------------------- | -------------------- |\n",
        "| 1  | `metric = keras.metrics.SparseCategoricalAccuracy()` | åˆ›å»ºæŒ‡æ ‡å¯¹è±¡               |\n",
        "| 2  | `metric.update_state(y_true, y_pred)`                | æ›´æ–°å†…éƒ¨çŠ¶æ€ï¼ˆç»Ÿè®¡æ­£ç¡®é¢„æµ‹æ•°ä¸æ€»æ ·æœ¬æ•°ï¼‰ |\n",
        "| 3  | `metric.result()`                                    | è®¡ç®—å½“å‰å‡†ç¡®ç‡              |\n",
        "| 4  | `metric.reset_state()`ï¼ˆæœªå±•ç¤ºï¼‰                          | æ¸…ç©ºç´¯è®¡ç»Ÿè®¡ï¼Œå‡†å¤‡ä¸‹ä¸€è½®è®¡ç®—       |\n",
        "\n",
        "---\n",
        "\n",
        "####### ğŸ’¡æ‹“å±•ï¼šå¦‚æœé¢„æµ‹ä¸å®Œå…¨æ­£ç¡®\n",
        "\n",
        "å‡å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "predictions = ops.array([[1, 0, 0], [0, 0, 1], [0, 1, 0]])\n",
        "```\n",
        "\n",
        "å³åªæœ‰ç¬¬ä¸€ä¸ªæ ·æœ¬é¢„æµ‹æ­£ç¡®ï¼Œ\n",
        "åˆ™ï¼š\n",
        "[\n",
        "\\text{accuracy} = \\frac{1}{3} \\approx 0.33\n",
        "]\n",
        "è¾“å‡ºä¼šå˜ä¸ºï¼š\n",
        "\n",
        "```\n",
        "result: 0.33\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vg0TsK_R1gOI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkPbZouI5vKZ"
      },
      "source": [
        "#### Using fit() with a custom training loop\n",
        "ç»“åˆè‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œå’Œkeraså†…ç½®å¾ªç¯çš„åŠŸèƒ½"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grYVptDr5vKZ"
      },
      "source": [
        "##### Customizing fit() with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_2XmPff5vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = loss_fn(targets, predictions)\n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply(gradients, self.trainable_weights)\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A6KEgF95vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def get_custom_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = CustomModel(inputs, outputs)\n",
        "    model.compile(optimizer=keras.optimizers.Adam())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djqk6SR05vKZ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "model = get_custom_model()\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDMjzAOA5vKa"
      },
      "source": [
        "##### Customizing fit() with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSNyI_5Z5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        predictions = self(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "\n",
        "        loss.backward()\n",
        "        trainable_weights = [v for v in self.trainable_weights]\n",
        "        gradients = [v.value.grad for v in trainable_weights]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.optimizer.apply(gradients, trainable_weights)\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI9d8rOb5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "def get_custom_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = CustomModel(inputs, outputs)\n",
        "    model.compile(optimizer=keras.optimizers.Adam())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPd5lPbi5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "model = get_custom_model()\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmu2qDQ85vKa"
      },
      "source": [
        "##### Customizing fit() with JAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DpZujlm5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def compute_loss_and_updates(\n",
        "        self,\n",
        "        trainable_variables,\n",
        "        non_trainable_variables,\n",
        "        inputs,\n",
        "        targets,\n",
        "        training=False,\n",
        "    ):\n",
        "        predictions, non_trainable_variables = self.stateless_call(\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            inputs,\n",
        "            training=training,\n",
        "        )\n",
        "        loss = loss_fn(targets, predictions)\n",
        "        return loss, non_trainable_variables\n",
        "\n",
        "    def train_step(self, state, data):\n",
        "        (\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            optimizer_variables,\n",
        "            metrics_variables,\n",
        "        ) = state\n",
        "        inputs, targets = data\n",
        "\n",
        "        grad_fn = jax.value_and_grad(\n",
        "            self.compute_loss_and_updates, has_aux=True\n",
        "        )\n",
        "\n",
        "        (loss, non_trainable_variables), grads = grad_fn(\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            inputs,\n",
        "            targets,\n",
        "            training=True,\n",
        "        )\n",
        "\n",
        "        (\n",
        "            trainable_variables,\n",
        "            optimizer_variables,\n",
        "        ) = self.optimizer.stateless_apply(\n",
        "            optimizer_variables, grads, trainable_variables\n",
        "        )\n",
        "\n",
        "        logs = {\"loss\": loss}\n",
        "        state = (\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            optimizer_variables,\n",
        "            metrics_variables,\n",
        "        )\n",
        "        return logs, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKOmVDTa5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "def get_custom_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = CustomModel(inputs, outputs)\n",
        "    model.compile(optimizer=keras.optimizers.Adam())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwIElYbV5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "model = get_custom_model()\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2NyAuVL5vKa"
      },
      "source": [
        "#### Handling metrics in a custom train_step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usMOhfu65vKa"
      },
      "source": [
        "##### train_step() metrics handling with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2Mh6Wir5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    # æ¯ä¸ªæ‰¹æ¬¡éƒ½ä¼šè°ƒç”¨\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compute_loss(y=targets, y_pred=predictions)\n",
        "\n",
        "        # å‘åä¼ æ’­ï¼Œæ¯ä¸ªæ‰¹æ¬¡éƒ½ä¼šæ›´æ–°æƒé‡\n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply(gradients, self.trainable_weights)\n",
        "\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(targets, predictions)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfp9Yi415vKa"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def get_custom_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = CustomModel(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = get_custom_model()\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ä»£ç è¯´æ˜"
      ],
      "metadata": {
        "id": "FNpq_prR2hQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„ Keras æ¨¡å‹ï¼Œé‡å†™äº†è®­ç»ƒæ­¥éª¤ä»¥å®ç°æ›´çµæ´»çš„è®­ç»ƒè¿‡ç¨‹ã€‚è®©æˆ‘é€éƒ¨åˆ†è¯¦ç»†è§£é‡Šï¼š\n",
        "\n",
        "####### ä»£ç ç»“æ„åˆ†æ\n",
        "\n",
        "######## 1. åŸºç¡€è®¾ç½®å’Œå¯¼å…¥\n",
        "```python\n",
        "%%backend tensorflow\n",
        "import keras\n",
        "from keras import layers\n",
        "```\n",
        "- `%%backend tensorflow`: åœ¨ Jupyter notebook ä¸­è®¾ç½®åç«¯ä¸º TensorFlow\n",
        "- å¯¼å…¥ Keras æ¡†æ¶å’Œå±‚æ¨¡å—\n",
        "\n",
        "######## 2. è‡ªå®šä¹‰æ¨¡å‹ç±»å®šä¹‰\n",
        "```python\n",
        "class CustomModel(keras.Model):\n",
        "```\n",
        "åˆ›å»ºä¸€ä¸ªç»§æ‰¿è‡ª `keras.Model` çš„è‡ªå®šä¹‰æ¨¡å‹ç±»\n",
        "\n",
        "######## 3. é‡å†™è®­ç»ƒæ­¥éª¤æ–¹æ³•\n",
        "```python\n",
        "def train_step(self, data):\n",
        "```\n",
        "é‡å†™ `train_step` æ–¹æ³•ï¼Œè¿™æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼Œæ¯ä¸ªæ‰¹æ¬¡(batch)éƒ½ä¼šè°ƒç”¨\n",
        "\n",
        "######## 4. æ•°æ®è§£åŒ…å’Œå‰å‘ä¼ æ’­\n",
        "```python\n",
        "inputs, targets = data\n",
        "with tf.GradientTape() as tape:\n",
        "    predictions = self(inputs, training=True)\n",
        "    loss = self.compute_loss(y=targets, y_pred=predictions)\n",
        "```\n",
        "- **æ•°æ®è§£åŒ…**: `inputs, targets = data` - å°†è¾“å…¥æ•°æ®åˆ†ä¸ºè¾“å…¥å’Œæ ‡ç­¾\n",
        "- **æ¢¯åº¦è®°å½•**: `tf.GradientTape()` - åˆ›å»ºæ¢¯åº¦è®°å½•ä¸Šä¸‹æ–‡ï¼Œè·Ÿè¸ªæ‰€æœ‰å¯è®­ç»ƒå˜é‡çš„æ“ä½œ\n",
        "- **å‰å‘ä¼ æ’­**: `self(inputs, training=True)` - è°ƒç”¨æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­\n",
        "- **æŸå¤±è®¡ç®—**: `self.compute_loss()` - ä½¿ç”¨æ¨¡å‹ç¼–è¯‘æ—¶å®šä¹‰çš„æŸå¤±å‡½æ•°è®¡ç®—æŸå¤±\n",
        "\n",
        "######## 5. åå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°\n",
        "```python\n",
        "gradients = tape.gradient(loss, self.trainable_weights)\n",
        "self.optimizer.apply(gradients, self.trainable_weights)\n",
        "```\n",
        "- **æ¢¯åº¦è®¡ç®—**: `tape.gradient()` - è®¡ç®—æŸå¤±ç›¸å¯¹äºæ‰€æœ‰å¯è®­ç»ƒæƒé‡çš„æ¢¯åº¦\n",
        "- **æƒé‡æ›´æ–°**: `optimizer.apply()` - ä½¿ç”¨ä¼˜åŒ–å™¨åº”ç”¨æ¢¯åº¦æ›´æ–°æƒé‡\n",
        "\n",
        "######## 6. æŒ‡æ ‡æ›´æ–°\n",
        "```python\n",
        "for metric in self.metrics:\n",
        "    if metric.name == \"loss\":\n",
        "        metric.update_state(loss)\n",
        "    else:\n",
        "        metric.update_state(targets, predictions)\n",
        "```\n",
        "- éå†æ‰€æœ‰åœ¨æ¨¡å‹ç¼–è¯‘æ—¶å®šä¹‰çš„æŒ‡æ ‡\n",
        "- å¦‚æœæ˜¯æŸå¤±æŒ‡æ ‡ï¼Œç›´æ¥ä½¿ç”¨è®¡ç®—å‡ºçš„æŸå¤±å€¼\n",
        "- å¯¹äºå…¶ä»–æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ï¼‰ï¼Œä½¿ç”¨çœŸå®æ ‡ç­¾å’Œé¢„æµ‹å€¼æ›´æ–°\n",
        "\n",
        "######## 7. è¿”å›è®­ç»ƒæŒ‡æ ‡\n",
        "```python\n",
        "return {m.name: m.result() for m in self.metrics}\n",
        "```\n",
        "è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„å½“å‰å€¼\n",
        "\n",
        "####### ä¸æ ‡å‡†è®­ç»ƒçš„åŒºåˆ«\n",
        "\n",
        "**æ ‡å‡† Keras è®­ç»ƒ**ï¼š\n",
        "- è‡ªåŠ¨å¤„ç†æ¢¯åº¦è®¡ç®—å’Œæƒé‡æ›´æ–°\n",
        "- å†…ç½®æŸå¤±è®¡ç®—å’ŒæŒ‡æ ‡æ›´æ–°\n",
        "\n",
        "**è‡ªå®šä¹‰è®­ç»ƒçš„ä¼˜åŠ¿**ï¼š\n",
        "1. **çµæ´»æ€§**: å¯ä»¥è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘\n",
        "2. **å¤æ‚åœºæ™¯**: æ”¯æŒå¤šä»»åŠ¡å­¦ä¹ ã€å¯¹æŠ—è®­ç»ƒç­‰å¤æ‚åœºæ™¯\n",
        "3. **è°ƒè¯•**: æ›´å®¹æ˜“è°ƒè¯•å’Œç›‘æ§è®­ç»ƒè¿‡ç¨‹\n",
        "4. **ç ”ç©¶**: é€‚åˆç ”ç©¶å’Œå®éªŒæ–°çš„è®­ç»ƒæ–¹æ³•\n",
        "\n",
        "####### ä½¿ç”¨ç¤ºä¾‹\n",
        "```python\n",
        "# åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹å®ä¾‹\n",
        "model = CustomModel()\n",
        "\n",
        "# ç¼–è¯‘æ¨¡å‹ï¼ˆå®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’ŒæŒ‡æ ‡ï¼‰\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy', 'loss']\n",
        ")\n",
        "\n",
        "# æ­£å¸¸è®­ç»ƒ\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "```\n",
        "\n",
        "è¿™ç§è‡ªå®šä¹‰è®­ç»ƒæ­¥éª¤çš„æ–¹å¼ä¸ºå¤æ‚çš„è®­ç»ƒåœºæ™¯æä¾›äº†æå¤§çš„çµæ´»æ€§ã€‚\n",
        "\n",
        "è‡ªå®šä¹‰è®­ç»ƒæ—¶ï¼Œéœ€è¦è‡ªå·±è®¡ç®—æŒ‡æ ‡å—ï¼Ÿ\n",
        "ä¸ç”¨"
      ],
      "metadata": {
        "id": "7fNN_Y1Q2i54"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGrNvFA_5vKa"
      },
      "source": [
        "##### train_step() metrics handling with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcB3dr_R5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        predictions = self(inputs, training=True)\n",
        "        loss = self.compute_loss(y=targets, y_pred=predictions)\n",
        "\n",
        "        loss.backward()\n",
        "        trainable_weights = [v for v in self.trainable_weights]\n",
        "        gradients = [v.value.grad for v in trainable_weights]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.optimizer.apply(gradients, trainable_weights)\n",
        "\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(targets, predictions)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvzU7vxz5vKa"
      },
      "outputs": [],
      "source": [
        "%%backend torch\n",
        "def get_custom_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = CustomModel(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = get_custom_model()\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ray36Sd5vKa"
      },
      "source": [
        "##### train_step() metrics handling with JAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi3g0rL65vKa"
      },
      "outputs": [],
      "source": [
        "%%backend jax\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def compute_loss_and_updates(\n",
        "        self,\n",
        "        trainable_variables,\n",
        "        non_trainable_variables,\n",
        "        inputs,\n",
        "        targets,\n",
        "        training=False,\n",
        "    ):\n",
        "        predictions, non_trainable_variables = self.stateless_call(\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            inputs,\n",
        "            training=training,\n",
        "        )\n",
        "        loss = self.compute_loss(y=targets, y_pred=predictions)\n",
        "        return loss, (predictions, non_trainable_variables)\n",
        "\n",
        "    def train_step(self, state, data):\n",
        "        (\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            optimizer_variables,\n",
        "            metrics_variables,\n",
        "        ) = state\n",
        "        inputs, targets = data\n",
        "\n",
        "        grad_fn = jax.value_and_grad(\n",
        "            self.compute_loss_and_updates, has_aux=True\n",
        "        )\n",
        "\n",
        "        (loss, (predictions, non_trainable_variables)), grads = grad_fn(\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            inputs,\n",
        "            targets,\n",
        "            training=True,\n",
        "        )\n",
        "        (\n",
        "            trainable_variables,\n",
        "            optimizer_variables,\n",
        "        ) = self.optimizer.stateless_apply(\n",
        "            optimizer_variables, grads, trainable_variables\n",
        "        )\n",
        "\n",
        "        new_metrics_vars = []\n",
        "        logs = {}\n",
        "        for metric in self.metrics:\n",
        "            num_prev = len(new_metrics_vars)\n",
        "            num_current = len(metric.variables)\n",
        "            current_vars = metrics_variables[num_prev : num_prev + num_current]\n",
        "            if metric.name == \"loss\":\n",
        "                current_vars = metric.stateless_update_state(current_vars, loss)\n",
        "            else:\n",
        "                current_vars = metric.stateless_update_state(\n",
        "                    current_vars, targets, predictions\n",
        "                )\n",
        "            logs[metric.name] = metric.stateless_result(current_vars)\n",
        "            new_metrics_vars += current_vars\n",
        "\n",
        "        state = (\n",
        "            trainable_variables,\n",
        "            non_trainable_variables,\n",
        "            optimizer_variables,\n",
        "            new_metrics_vars,\n",
        "        )\n",
        "        return logs, state"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter07_deep-dive-keras",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}